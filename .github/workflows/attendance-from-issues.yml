name: Build attendance codes from issues

on:
  issues:
    types: [opened, edited]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to process when running manually'
        required: false
  issue_comment:
    types: [created, edited]

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  parse-and-commit:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Verify tooling
        run: |
          set -euo pipefail
          git --version
          gh --version || echo "gh CLI not found"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Parse issue and commit codes JSON
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          DISPATCH_ISSUE_NUMBER: ${{ inputs.issue_number }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_BODY: ${{ github.event.issue.body }}
          COMMENT_BODY: ${{ github.event.comment.body }}
          REPO: ${{ github.repository }}
          TARGET_BRANCH: main
        run: |
          set -euo pipefail
          python3 - << 'PY'
          import os, re, json, subprocess, sys, pathlib, urllib.request, urllib.error, base64

          # Determine issue number from event (issues trigger) or manual input (workflow_dispatch)
          issue_no_raw = os.environ.get('ISSUE_NUMBER') or ''
          if not issue_no_raw.strip():
              issue_no_raw = os.environ.get('DISPATCH_ISSUE_NUMBER') or ''
          if not issue_no_raw.strip():
              print('No issue number provided in event or inputs; exiting without changes.')
              sys.exit(0)
          issue_no = int(issue_no_raw)
          repo = os.environ['REPO']
          title = os.environ.get('ISSUE_TITLE') or ''
          body = os.environ.get('ISSUE_BODY') or ''
          comment_body = os.environ.get('COMMENT_BODY') or ''
          # If title/body are missing (e.g., workflow_dispatch), fetch them via API
          if not title or not body:
              gh_token = os.environ.get('GITHUB_TOKEN') or os.environ.get('GH_TOKEN')
              api_path = f"https://api.github.com/repos/{repo}/issues/{issue_no}"
              try:
                  # Prefer gh if available
                  out = subprocess.run(['gh','api', f'repos/{repo}/issues/{issue_no}'], capture_output=True, text=True, check=True)
                  issue_json = json.loads(out.stdout)
                  title = title or issue_json.get('title') or ''
                  body = body or issue_json.get('body') or ''
              except Exception:
                  if gh_token:
                      req = urllib.request.Request(api_path, headers={
                          'Authorization': f'Bearer {gh_token}',
                          'Accept': 'application/vnd.github+json',
                          'User-Agent': 'attendance-bot'
                      })
                      with urllib.request.urlopen(req) as resp:
                          issue_json = json.loads(resp.read().decode('utf-8'))
                          title = title or issue_json.get('title') or ''
                          body = body or issue_json.get('body') or ''
          target_branch = os.environ.get('TARGET_BRANCH','main')

          def parse_issue_form_text(body_text: str):
              """Parse GitHub Issue Form sections: Course code, Week number, Attendance codes.

              Returns (course:str|None, week:str|None, pairs:list[(slot,code)]).
              """
              course = None
              week = None
              pairs = []

              # Common Issue Forms render as markdown headings like:
              # ### Course code\nFIT1111\n\n### Week number\n3\n\n### Attendance codes\n...
              sec = {
                  'course': r"(?mis)^###\s*Course\s*code\s*\n+([^\n#]+)",
                  'week': r"(?mis)^###\s*Week\s*number\s*\n+([^\n#]+)",
                  'codes': r"(?mis)^###\s*Attendance\s*codes\s*\n+(.+?)(?:\n###\s|\Z)",
              }
              m = re.search(sec['course'], body_text)
              if m:
                  course = re.sub(r"[^A-Za-z0-9]+", "", m.group(1)).upper() or None
              m = re.search(sec['week'], body_text)
              if m:
                  wk = re.sub(r"[^0-9]+", "", m.group(1))
                  week = wk if wk else None
              m = re.search(sec['codes'], body_text)
              if m:
                  code_block = m.group(1)
                  for line in code_block.splitlines():
                      line = line.strip()
                      if not line:
                          continue
                      # Accept optional list markers and flexible spacing
                      # Allow ASCII colon ':', full-width colon '：', hyphen '-', en dash '–', em dash '—'
                      mm = re.match(r"^[-*+]?\s*([^:：\-–—]+?)\s*(?:[:：\-–—])\s*([A-Za-z0-9]{4,12})\s*$", line)
                      if mm:
                          slot, code = mm.group(1).strip(), mm.group(2).strip().upper()
                          pairs.append((slot, code))
              return course, week, pairs

          def parse_markdown_table(body_text: str):
              """Parse simple Markdown tables and take rightmost column as code.

              Returns pairs list.
              """
              pairs = []
              lines = [ln.rstrip() for ln in body_text.splitlines()]
              # Find table blocks: look for a header with '|' and a separator with dashes
              i = 0
              while i < len(lines):
                  if '|' in lines[i]:
                      header = lines[i]
                      if i + 1 < len(lines) and re.search(r"\|\s*-{2,}", lines[i+1]):
                          j = i + 2
                          while j < len(lines) and '|' in lines[j] and lines[j].strip().startswith('|') or '|' in lines[j]:
                              row = lines[j]
                              cols = [c.strip() for c in row.strip().strip('|').split('|')]
                              if len(cols) >= 2:
                                  code = re.sub(r"[^A-Za-z0-9]+", "", cols[-1]).upper()
                                  # pick first non-empty as slot
                                  slot = next((c for c in cols if c), '')
                                  if slot and code:
                                      pairs.append((slot, code))
                              j += 1
                          i = j
                          continue
                  i += 1
              return pairs

          def parse_task_list(body_text: str):
              """Parse GitHub task list items for attendance entries.

              Accepts lines like:
              - [x] Workshop 01, Mon 2025-08-18 18:00, code GGGQK
              - [ ] Laboratory 07, Wed 2025-08-20 16:00 code Q6TJA

              Returns (items, has_tasks, checked_count) where items is a list of
              dicts: {slot, code, date}. Only checked items are returned.
              """
              items = []
              has_tasks = False
              checked_count = 0
              for raw in body_text.splitlines():
                  m = re.match(r"^\s*-\s*\[(?P<checked>[ xX])\]\s*(?P<rest>.+)$", raw)
                  if not m:
                      continue
                  has_tasks = True
                  checked = m.group('checked').lower() == 'x'
                  rest = m.group('rest').strip()
                  code_match = re.search(r"(?:\bcode\b[:\s]*|[ ,])([A-Za-z0-9]{4,12})\s*$", rest, flags=re.I)
                  code_val = code_match.group(1).upper() if code_match else None
                  date_match = re.search(r"(20\d{2}-\d{2}-\d{2})", rest)
                  date_val = date_match.group(1) if date_match else None
                  slot_part = rest
                  if date_match:
                      slot_part = rest[:date_match.start()].rstrip(' ,')
                  elif code_match:
                      slot_part = rest[:code_match.start()].rstrip(' ,')
                  slot_val = slot_part.split(',')[0].strip()
                  if checked and slot_val and code_val:
                      checked_count += 1
                      items.append({'slot': slot_val, 'code': re.sub(r"[^A-Za-z0-9]+","", code_val).upper(), 'date': date_val})
              return items, has_tasks, checked_count

          def call_gemini_api(api_key, issue_title, issue_body):
              prompt = f'''
              Task: From the GitHub Issue content below, extract the course code, week number (integer), and attendance codes.

              Rules and format:
              - course: a 3-letter + 4-digit code (e.g., FIT1111).
              - week: integer only (e.g., "Week 3" -> 3).
              - codes: an array of objects, each with:
                - slot: the row/group/session name (e.g., "Workshop 1", "Applied 2").
                - code: the attendance code (alphanumeric only, uppercase).
              - If the body describes a table and says the rightmost column is the code, parse rows accordingly: take the rightmost column as code, and the left-most descriptive column as slot. Ignore headers.
              - If course or week is missing, set it to null. If no codes found, return [].
              - Return a single, minified JSON object only (no Markdown or explanation).

              Output JSON keys: "course", "week", "codes".

              ---
              Issue Title: {issue_title}
              ---
              Issue Body:
              {issue_body}
              '''
              
              api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={api_key}"
              
              headers = {
                  "Content-Type": "application/json",
                  "x-goog-api-key": api_key,
                  "User-Agent": "always-attend-bot/1.0"
              }
              
              data = {
                  "contents": [{
                      "role": "user",
                      "parts": [{
                          "text": prompt
                      }]
                  }],
                  "generationConfig": {
                      "responseMimeType": "application/json",
                  }
              }
              
              req = urllib.request.Request(api_url, data=json.dumps(data).encode("utf-8"), headers=headers)
              
              try:
                  with urllib.request.urlopen(req) as response:
                      if response.status == 200:
                          response_body = response.read().decode("utf-8")
                          response_json = json.loads(response_body)
                          return response_json['candidates'][0]['content']['parts'][0]['text']
              except urllib.error.HTTPError as e:
                  print(f"Gemini API request failed with status: {e.code}")
                  print(e.read().decode())
                  return None
              except Exception as e:
                  print(f"An unexpected error occurred: {e}")
                  return None

          def call_gemini_api_with_image(api_key, image_data, mime_type):
              prompt = '''
              Task: Extract attendance data from the attached table screenshot and output strict JSON only.

              Parsing rules (table-focused):
              - Treat the rightmost column as the attendance code (code). Ignore similar text in other columns.
              - For each row, set slot to the row's session/group/time label (usually a left-most descriptive column, e.g., "Workshop 1", "Applied 2", "Lab A").
              - Set code to the value from the rightmost column (alphanumeric, uppercase). Ignore header, empty, or separator rows.

              Other fields:
              - course: extract a 3-letters + 4-digits code like FIT1111 if present; otherwise null.
              - week: extract an integer week number if present; otherwise null.

              Output requirements: return only minified JSON, no Markdown, no prose. Shape:
              {"course": string|null, "week": integer|null, "codes": [{"slot": string, "code": string}]}
              '''
              
              api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={api_key}"
              
              headers = {
                  "Content-Type": "application/json",
                  "x-goog-api-key": api_key,
                  "User-Agent": "always-attend-bot/1.0"
              }
              
              data = {
                  "contents": [{
                      "role": "user",
                      "parts": [
                          {"text": prompt},
                          {
                              "inlineData": {
                                  "mimeType": mime_type,
                                  "data": image_data
                              }
                          }
                      ]
                  }],
                  "generationConfig": {
                      "responseMimeType": "application/json",
                  }
              }
              
              req = urllib.request.Request(api_url, data=json.dumps(data).encode("utf-8"), headers=headers)
              
              try:
                  with urllib.request.urlopen(req) as response:
                      if response.status == 200:
                          response_body = response.read().decode("utf-8")
                          response_json = json.loads(response_body)
                          return response_json['candidates'][0]['content']['parts'][0]['text']
              except urllib.error.HTTPError as e:
                  print(f"Gemini API request failed with status: {e.code}")
                  print(e.read().decode())
                  return None

          

          def parse_extracted_json(text):
              # Accept raw JSON, fenced code blocks, or JSON embedded in prose
              s = (text or '').strip()
              # Strip common code fences
              if s.startswith('```'):
                  s = s.strip('`')
                  # remove possible language hint
                  s = re.sub(r"^json\n", "", s, flags=re.I)
              # Try direct JSON
              try:
                  data = json.loads(s)
              except Exception:
                  # Fallback: find the first JSON object in text
                  m = re.search(r"\{[\s\S]*\}", s)
                  if not m:
                      return None, None, []
                  try:
                      data = json.loads(m.group(0))
                  except Exception:
                      return None, None, []
              course = data.get("course")
              week_val = data.get("week")
              week = str(week_val) if (isinstance(week_val, int) or (isinstance(week_val, str) and week_val.strip())) else None
              pairs = []
              codes = data.get("codes")
              if isinstance(codes, dict):
                  for k, v in codes.items():
                      slot = str(k).strip()
                      code = re.sub(r"[^A-Za-z0-9]+", "", str(v)).upper()
                      if slot and code:
                          pairs.append((slot, code))
              elif isinstance(codes, list):
                  for item in codes:
                      if isinstance(item, dict):
                          slot = (item.get("slot") or item.get("name") or item.get("label") or "").strip()
                          code = (item.get("code") or item.get("value") or "").strip().upper()
                          code = re.sub(r"[^A-Za-z0-9]+", "", code)
                          if slot and code:
                              pairs.append((slot, code))
                      elif isinstance(item, (list, tuple)) and len(item) >= 2:
                          slot = str(item[0]).strip()
                          code = re.sub(r"[^A-Za-z0-9]+", "", str(item[-1])).upper()
                          if slot and code:
                              pairs.append((slot, code))
              return course, week, pairs

          # Aggregate text: issue body + latest comment (if present) for parsing
          aggregate_text = body
          if comment_body:
              aggregate_text += "\n\n" + comment_body

          # First, try deterministic parsing from the Issue Form
          course, week, pairs = parse_issue_form_text(aggregate_text)

          gemini_api_key = os.environ.get('GEMINI_API_KEY')
          gemini_used = False
          # Task list parsing with explicit user confirmation via checkboxes
          task_items_selected = []
          date_by_pair = {}
          task_items, has_tasks, checked_count = parse_task_list(aggregate_text)
          if has_tasks:
              if checked_count == 0:
                  comment = (
                      "Task list detected. Please tick (check) the items you want to commit to the database.\n\n"
                      "Example: `- [x] Workshop 01, Mon 2025-08-18 18:00, code GGGQK`\n\n"
                      "After you check the boxes, edit/save the issue; the workflow will run again and generate the JSON."
                  )
                  subprocess.run([
                      'gh','api', f'repos/{repo}/issues/{issue_no}/comments',
                      '--method','POST','-f',f'body={comment}'
                  ], check=False)
                  sys.exit(0)
              # Use only checked items
              task_items_selected = task_items
              pairs = []
              for it in task_items_selected:
                  pairs.append((it['slot'], it['code']))
                  if it.get('date'):
                      date_by_pair[(it['slot'], it['code'])] = it['date']

          # Image-first: try OCR on any attached images before text parsing
          if not pairs:
              md_imgs = re.findall(r'!\[[^\]]*\]\((https?://[^)\s]+)\)', aggregate_text)
              plain_imgs = re.findall(r'(https?://[^\s)\]>\]]+\.(?:png|jpg|jpeg|webp|gif))', aggregate_text, flags=re.I)
              gh_assets = re.findall(r'(https?://github\.com/[^\s)\]>\]]+/assets/[^\s)\]>\]]+)', aggregate_text)
              # Merge and sanitize trailing punctuation like quotes or parentheses
              tmp = md_imgs + plain_imgs + gh_assets
              img_urls = []
              for u in tmp:
                  su = u.strip().strip('\"\'').rstrip(').,')
                  if su and su not in img_urls:
                      img_urls.append(su)

              def try_fetch_image(url: str):
                  """Fetch image bytes with fallbacks for GitHub user-attachments.

                  1) Try with auth on GitHub domains.
                  2) Retry without Authorization on failure.
                  3) Retry with ?download=1 for direct CDN redirect.
                  Returns (bytes, content_type) or (None, None).
                  """
                  headers_base = {"User-Agent": "always-attend-bot/1.0", "Accept": "*/*"}
                  gh_token = os.environ.get('GITHUB_TOKEN') or os.environ.get('GH_TOKEN')
                  is_gh = ("github.com" in url) or ("user-attachments" in url) or ("githubusercontent.com" in url)
                  attempts = []
                  if is_gh and gh_token:
                      h = dict(headers_base)
                      h["Authorization"] = f"Bearer {gh_token}"
                      attempts.append((url, h))
                  attempts.append((url, dict(headers_base)))
                  if ("?" not in url) and is_gh:
                      attempts.append((url + "?download=1", dict(headers_base)))
                  last_err = None
                  for u_try, h_try in attempts:
                      try:
                          req_try = urllib.request.Request(u_try, headers=h_try)
                          with urllib.request.urlopen(req_try) as resp_try:
                              data = resp_try.read()
                              ctype = resp_try.info().get_content_type()
                              return data, ctype
                      except urllib.error.HTTPError as e:
                          last_err = f"HTTP {e.code}"
                      except Exception as e:
                          last_err = str(e)
                  if last_err:
                      print(f"DEBUG: image fetch attempts failed for {url}: {last_err}")
                  return None, None

              if img_urls:
                  if not gemini_api_key:
                      print("Image(s) found but no GEMINI_API_KEY set; skipping OCR.")
                  for url in img_urls:
                      try:
                          print(f"DEBUG: fetching image {url}")
                          image_bytes, content_type = try_fetch_image(url)
                          if not image_bytes:
                              raise RuntimeError("could not fetch image bytes")
                          image_b64 = base64.b64encode(image_bytes).decode("utf-8")
                          if gemini_api_key:
                              txt = call_gemini_api_with_image(gemini_api_key, image_b64, content_type or 'image/png')
                              if txt:
                                  c, w, p = parse_extracted_json(txt)
                                  print(f"DEBUG: gemini image JSON length={len(txt)} codes={len(p)}")
                                  if p:
                                      if not course:
                                          course = c
                                      if not week:
                                          week = w
                                      if not pairs:
                                          pairs = p
                                      gemini_used = True
                          if pairs:
                              break
                      except Exception as e:
                          print(f"Failed to process image at {url}: {e}")

          # If still missing, try deterministic Markdown table parsing
          if not pairs:
              md_pairs = parse_markdown_table(aggregate_text)
              if md_pairs:
                  pairs = md_pairs

          # If still missing, optionally try Gemini on text
          if (not course or not week or not pairs) and gemini_api_key:
              txt = call_gemini_api(gemini_api_key, title, aggregate_text)
              if txt:
                  c, w, p = parse_extracted_json(txt)
                  print(f"DEBUG: gemini text JSON length={len(txt)} codes={len(p)}")
                  if p and not pairs:
                      pairs = p
                  if not course and c:
                      course = c
                  if not week and w:
                      week = w
                  gemini_used = True

          

          # If still no pairs, ask user to provide proper text
          if not pairs:
              comment = (
                  "Could not identify attendance codes from the issue.\n\n"
                  "Please provide the codes in the issue body in the following format, or upload a clearer screenshot:\n\n"
                  "```\nWorkshop 1: JZXBA\nWorkshop 2: AJYV7\nApplied 1: 6B7UF\n...\n```\n\nAlso, please specify the following in the body:\n\n- Course code (e.g., FIT1111)\n- Week number (e.g., Week 3)\n\nThe workflow will automatically retry after the issue is updated."
              )
              subprocess.run([
                  'gh','api',
                  f'repos/{repo}/issues/{issue_no}/comments',
                  '--method','POST','-f',f'body={comment}'
              ], check=False)
              sys.exit(0)

          # If pairs are found but course/week missing, request them
          if not course or not week:
            missing = []
            if not course: missing.append('课程代码（如 FIT1111）')
            if not week: missing.append('Week 编号（如 Week 3）')
            comment = (
              "Attendance codes have been identified, but the following information is missing: " + ", ".join(missing) + ".\n\n"
              "Please add the missing information to the issue body:\n\n- Course code (e.g., FIT1111)\n- Week number (e.g., Week 3)\n\nThe JSON file will be generated automatically after the issue is updated."
            )
            subprocess.run([
              'gh','api',
              f'repos/{repo}/issues/{issue_no}/comments',
              '--method','POST','-f',f'body={comment}'
            ], check=False)
            sys.exit(0)

          # Update issue title
          new_title = f"{course} Week {week}: Attendance codes"
          subprocess.run([
            'gh','issue','edit',str(issue_no),
            '--title', new_title
          ], check=False)

          # Build JSON entries for codes (include date from task list when available)
          entries = []
          if 'task_items_selected' in locals() and task_items_selected:
            for it in task_items_selected:
              item = {'slot': it['slot'].strip(), 'code': it['code'].strip().upper()}
              if it.get('date'):
                item['date'] = it['date']
              entries.append(item)
          else:
            for slot, code in pairs:
              item = {'slot': slot.strip(), 'code': code.strip().upper()}
              d = date_by_pair.get((slot, code)) if 'date_by_pair' in locals() else None
              if d:
                item['date'] = d
              entries.append(item)

          # File path under data/{course}/{week}.json
          safe_course = re.sub(r'[^A-Za-z0-9]+','', course).upper()
          safe_week = re.sub(r'[^0-9]+','', week)
          if not safe_week:
            raise SystemExit('Week number must be an integer')
          out_dir = pathlib.Path('data') / safe_course
          out_dir.mkdir(parents=True, exist_ok=True)
          filename = str(out_dir / f"{safe_week}.json")
          with open(filename,'w',encoding='utf-8') as f:
            json.dump(entries, f, ensure_ascii=False, indent=2)

          # Commit and push (with PR fallback if branch protection blocks direct push)
          subprocess.run(['git','config','user.name','github-actions[bot]'], check=True)
          subprocess.run(['git','config','user.email','41898282+github-actions[bot]@users.noreply.github.com'], check=True)
          subprocess.run(['git','fetch','origin', target_branch], check=False)
          subprocess.run(['git','checkout', target_branch], check=False)
          subprocess.run(['git','pull','--ff-only','origin', target_branch], check=False)
          subprocess.run(['git','add', filename], check=True)
          msg = f"[bot] add attendance codes for {course} Week {week} (issue #{issue_no})"
          subprocess.run(['git','commit','-m', msg], check=True)

          direct_push_ok = True
          try:
              subprocess.run(['git','push','origin', target_branch], check=True)
          except subprocess.CalledProcessError:
              direct_push_ok = False

          pr_url = None
          if not direct_push_ok:
              # Create a branch and open a PR
              safe_course = re.sub(r'[^A-Za-z0-9]+','', course).upper()
              safe_week = re.sub(r'[^0-9]+','', week)
              branch_name = f"bot/codes-{safe_course}-w{safe_week}-issue-{issue_no}"
              subprocess.run(['git','checkout','-b', branch_name], check=True)
              try:
                  subprocess.run(['git','push','-u','origin', branch_name], check=True)
                  # Create PR
                  pr_create = subprocess.run([
                      'gh','pr','create',
                      '--title', msg,
                      '--body', f"Automated codes JSON for {course} Week {week} (from issue #{issue_no}).",
                      '--base', target_branch,
                      '--head', branch_name
                  ], check=True, capture_output=True, text=True)
                  pr_url = pr_create.stdout.strip().splitlines()[-1]
              except subprocess.CalledProcessError as e:
                  print('Failed to create PR:', e)

          # Comment success with raw URL hint
          raw = f"https://raw.githubusercontent.com/{repo}/{target_branch}/{filename}"
          ok = (
            f"Generated codes JSON: `{filename}`\n\n"
            f"Raw URL: {raw}\n\n"
            f"The script can use this URL directly by setting `CODES_URL={raw}`."
          )
          if 'task_items_selected' in locals() and task_items_selected:
              ok += ("\n\nSource: checked GitHub task list items. You can uncheck items to exclude them and re-run by editing the issue.")
          if gemini_used:
              ok += ("\n\n"
                     "Note: Parsed with Gemini 2.5 Flash — please double-check the course, week, and codes for accuracy. "
                     "If anything looks wrong, edit the issue/comment and the workflow will regenerate the JSON.")
          
          if pr_url:
              ok += f"\n\nDirect push was blocked; opened PR: {pr_url}"
          subprocess.run([
            'gh','api',
            f'repos/{repo}/issues/{issue_no}/comments',
            '--method','POST','-f',f'body={ok}'
          ], check=False)
          PY
